{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33367e5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 447541328.00000, saving model to ./model/01-447541328.0000.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 447541328.00000 to 447529056.00000, saving model to ./model/02-447529056.0000.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 447529056.00000 to 447505904.00000, saving model to ./model/03-447505904.0000.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 447505904.00000 to 447468964.00000, saving model to ./model/04-447468964.0000.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 447468964.00000 to 447408984.00000, saving model to ./model/05-447408984.0000.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 447408984.00000 to 447315908.00000, saving model to ./model/06-447315908.0000.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 447315908.00000 to 447177316.00000, saving model to ./model/07-447177316.0000.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 447177316.00000 to 446976512.00000, saving model to ./model/08-446976512.0000.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 446976512.00000 to 446704352.00000, saving model to ./model/09-446704352.0000.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 446704352.00000 to 446337960.00000, saving model to ./model/10-446337960.0000.hdf5\n",
      "\n",
      "Epoch 00011: val_loss improved from 446337960.00000 to 445867620.00000, saving model to ./model/11-445867620.0000.hdf5\n",
      "\n",
      "Epoch 00012: val_loss improved from 445867620.00000 to 445281372.00000, saving model to ./model/12-445281372.0000.hdf5\n",
      "\n",
      "Epoch 00013: val_loss improved from 445281372.00000 to 444562280.00000, saving model to ./model/13-444562280.0000.hdf5\n",
      "\n",
      "Epoch 00014: val_loss improved from 444562280.00000 to 443694044.00000, saving model to ./model/14-443694044.0000.hdf5\n",
      "\n",
      "Epoch 00015: val_loss improved from 443694044.00000 to 442652448.00000, saving model to ./model/15-442652448.0000.hdf5\n",
      "\n",
      "Epoch 00016: val_loss improved from 442652448.00000 to 441441980.00000, saving model to ./model/16-441441980.0000.hdf5\n",
      "\n",
      "Epoch 00017: val_loss improved from 441441980.00000 to 440066404.00000, saving model to ./model/17-440066404.0000.hdf5\n",
      "\n",
      "Epoch 00018: val_loss improved from 440066404.00000 to 438514708.00000, saving model to ./model/18-438514708.0000.hdf5\n",
      "\n",
      "Epoch 00019: val_loss improved from 438514708.00000 to 436745980.00000, saving model to ./model/19-436745980.0000.hdf5\n",
      "\n",
      "Epoch 00020: val_loss improved from 436745980.00000 to 434806168.00000, saving model to ./model/20-434806168.0000.hdf5\n",
      "\n",
      "Epoch 00021: val_loss improved from 434806168.00000 to 432636048.00000, saving model to ./model/21-432636048.0000.hdf5\n",
      "\n",
      "Epoch 00022: val_loss improved from 432636048.00000 to 430247172.00000, saving model to ./model/22-430247172.0000.hdf5\n",
      "\n",
      "Epoch 00023: val_loss improved from 430247172.00000 to 427635288.00000, saving model to ./model/23-427635288.0000.hdf5\n",
      "\n",
      "Epoch 00024: val_loss improved from 427635288.00000 to 424837460.00000, saving model to ./model/24-424837460.0000.hdf5\n",
      "\n",
      "Epoch 00025: val_loss improved from 424837460.00000 to 421770264.00000, saving model to ./model/25-421770264.0000.hdf5\n",
      "\n",
      "Epoch 00026: val_loss improved from 421770264.00000 to 418483768.00000, saving model to ./model/26-418483768.0000.hdf5\n",
      "\n",
      "Epoch 00027: val_loss improved from 418483768.00000 to 414976832.00000, saving model to ./model/27-414976832.0000.hdf5\n",
      "\n",
      "Epoch 00028: val_loss improved from 414976832.00000 to 411189492.00000, saving model to ./model/28-411189492.0000.hdf5\n",
      "\n",
      "Epoch 00029: val_loss improved from 411189492.00000 to 407189044.00000, saving model to ./model/29-407189044.0000.hdf5\n",
      "\n",
      "Epoch 00030: val_loss improved from 407189044.00000 to 402863400.00000, saving model to ./model/30-402863400.0000.hdf5\n",
      "\n",
      "Epoch 00031: val_loss improved from 402863400.00000 to 398405600.00000, saving model to ./model/31-398405600.0000.hdf5\n",
      "\n",
      "Epoch 00032: val_loss improved from 398405600.00000 to 393532316.00000, saving model to ./model/32-393532316.0000.hdf5\n",
      "\n",
      "Epoch 00033: val_loss improved from 393532316.00000 to 388510984.00000, saving model to ./model/33-388510984.0000.hdf5\n",
      "\n",
      "Epoch 00034: val_loss improved from 388510984.00000 to 383287060.00000, saving model to ./model/34-383287060.0000.hdf5\n",
      "\n",
      "Epoch 00035: val_loss improved from 383287060.00000 to 377733752.00000, saving model to ./model/35-377733752.0000.hdf5\n",
      "\n",
      "Epoch 00036: val_loss improved from 377733752.00000 to 371893508.00000, saving model to ./model/36-371893508.0000.hdf5\n",
      "\n",
      "Epoch 00037: val_loss improved from 371893508.00000 to 366012644.00000, saving model to ./model/37-366012644.0000.hdf5\n",
      "\n",
      "Epoch 00038: val_loss improved from 366012644.00000 to 359770804.00000, saving model to ./model/38-359770804.0000.hdf5\n",
      "\n",
      "Epoch 00039: val_loss improved from 359770804.00000 to 353268964.00000, saving model to ./model/39-353268964.0000.hdf5\n",
      "\n",
      "Epoch 00040: val_loss improved from 353268964.00000 to 346584692.00000, saving model to ./model/40-346584692.0000.hdf5\n",
      "\n",
      "Epoch 00041: val_loss improved from 346584692.00000 to 339751952.00000, saving model to ./model/41-339751952.0000.hdf5\n",
      "\n",
      "Epoch 00042: val_loss improved from 339751952.00000 to 332598932.00000, saving model to ./model/42-332598932.0000.hdf5\n",
      "\n",
      "Epoch 00043: val_loss improved from 332598932.00000 to 325317720.00000, saving model to ./model/43-325317720.0000.hdf5\n",
      "\n",
      "Epoch 00044: val_loss improved from 325317720.00000 to 317792036.00000, saving model to ./model/44-317792036.0000.hdf5\n",
      "\n",
      "Epoch 00045: val_loss improved from 317792036.00000 to 310139984.00000, saving model to ./model/45-310139984.0000.hdf5\n",
      "\n",
      "Epoch 00046: val_loss improved from 310139984.00000 to 302374432.00000, saving model to ./model/46-302374432.0000.hdf5\n",
      "\n",
      "Epoch 00047: val_loss improved from 302374432.00000 to 294391304.00000, saving model to ./model/47-294391304.0000.hdf5\n",
      "\n",
      "Epoch 00048: val_loss improved from 294391304.00000 to 286347454.00000, saving model to ./model/48-286347454.0000.hdf5\n",
      "\n",
      "Epoch 00049: val_loss improved from 286347454.00000 to 278114316.00000, saving model to ./model/49-278114316.0000.hdf5\n",
      "\n",
      "Epoch 00050: val_loss improved from 278114316.00000 to 269710918.00000, saving model to ./model/50-269710918.0000.hdf5\n",
      "\n",
      "Epoch 00051: val_loss improved from 269710918.00000 to 261323352.00000, saving model to ./model/51-261323352.0000.hdf5\n",
      "\n",
      "Epoch 00052: val_loss improved from 261323352.00000 to 252963660.00000, saving model to ./model/52-252963660.0000.hdf5\n",
      "\n",
      "Epoch 00053: val_loss improved from 252963660.00000 to 244380396.00000, saving model to ./model/53-244380396.0000.hdf5\n",
      "\n",
      "Epoch 00054: val_loss improved from 244380396.00000 to 235962728.00000, saving model to ./model/54-235962728.0000.hdf5\n",
      "\n",
      "Epoch 00055: val_loss improved from 235962728.00000 to 227468924.00000, saving model to ./model/55-227468924.0000.hdf5\n",
      "\n",
      "Epoch 00056: val_loss improved from 227468924.00000 to 218747508.00000, saving model to ./model/56-218747508.0000.hdf5\n",
      "\n",
      "Epoch 00057: val_loss improved from 218747508.00000 to 210281050.00000, saving model to ./model/57-210281050.0000.hdf5\n",
      "\n",
      "Epoch 00058: val_loss improved from 210281050.00000 to 201835748.00000, saving model to ./model/58-201835748.0000.hdf5\n",
      "\n",
      "Epoch 00059: val_loss improved from 201835748.00000 to 193535666.00000, saving model to ./model/59-193535666.0000.hdf5\n",
      "\n",
      "Epoch 00060: val_loss improved from 193535666.00000 to 185216766.00000, saving model to ./model/60-185216766.0000.hdf5\n",
      "\n",
      "Epoch 00061: val_loss improved from 185216766.00000 to 177016974.00000, saving model to ./model/61-177016974.0000.hdf5\n",
      "\n",
      "Epoch 00062: val_loss improved from 177016974.00000 to 168877420.00000, saving model to ./model/62-168877420.0000.hdf5\n",
      "\n",
      "Epoch 00063: val_loss improved from 168877420.00000 to 160728816.00000, saving model to ./model/63-160728816.0000.hdf5\n",
      "\n",
      "Epoch 00064: val_loss improved from 160728816.00000 to 152859735.00000, saving model to ./model/64-152859735.0000.hdf5\n",
      "\n",
      "Epoch 00065: val_loss improved from 152859735.00000 to 145012795.00000, saving model to ./model/65-145012795.0000.hdf5\n",
      "\n",
      "Epoch 00066: val_loss improved from 145012795.00000 to 137473614.00000, saving model to ./model/66-137473614.0000.hdf5\n",
      "\n",
      "Epoch 00067: val_loss improved from 137473614.00000 to 130004554.00000, saving model to ./model/67-130004554.0000.hdf5\n",
      "\n",
      "Epoch 00068: val_loss improved from 130004554.00000 to 122890115.00000, saving model to ./model/68-122890115.0000.hdf5\n",
      "\n",
      "Epoch 00069: val_loss improved from 122890115.00000 to 115783307.00000, saving model to ./model/69-115783307.0000.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00070: val_loss improved from 115783307.00000 to 109092551.00000, saving model to ./model/70-109092551.0000.hdf5\n",
      "\n",
      "Epoch 00071: val_loss improved from 109092551.00000 to 102468932.00000, saving model to ./model/71-102468932.0000.hdf5\n",
      "\n",
      "Epoch 00072: val_loss improved from 102468932.00000 to 96086467.00000, saving model to ./model/72-96086467.0000.hdf5\n",
      "\n",
      "Epoch 00073: val_loss improved from 96086467.00000 to 90013767.00000, saving model to ./model/73-90013767.0000.hdf5\n",
      "\n",
      "Epoch 00074: val_loss improved from 90013767.00000 to 84139458.00000, saving model to ./model/74-84139458.0000.hdf5\n",
      "\n",
      "Epoch 00075: val_loss improved from 84139458.00000 to 78558095.00000, saving model to ./model/75-78558095.0000.hdf5\n",
      "\n",
      "Epoch 00076: val_loss improved from 78558095.00000 to 73109098.50000, saving model to ./model/76-73109098.5000.hdf5\n",
      "\n",
      "Epoch 00077: val_loss improved from 73109098.50000 to 68072305.00000, saving model to ./model/77-68072305.0000.hdf5\n",
      "\n",
      "Epoch 00078: val_loss improved from 68072305.00000 to 63233589.50000, saving model to ./model/78-63233589.5000.hdf5\n",
      "\n",
      "Epoch 00079: val_loss improved from 63233589.50000 to 58674762.00000, saving model to ./model/79-58674762.0000.hdf5\n",
      "\n",
      "Epoch 00080: val_loss improved from 58674762.00000 to 54430864.50000, saving model to ./model/80-54430864.5000.hdf5\n",
      "\n",
      "Epoch 00081: val_loss improved from 54430864.50000 to 50321548.00000, saving model to ./model/81-50321548.0000.hdf5\n",
      "\n",
      "Epoch 00082: val_loss improved from 50321548.00000 to 46596882.00000, saving model to ./model/82-46596882.0000.hdf5\n",
      "\n",
      "Epoch 00083: val_loss improved from 46596882.00000 to 43063906.00000, saving model to ./model/83-43063906.0000.hdf5\n",
      "\n",
      "Epoch 00084: val_loss improved from 43063906.00000 to 39780772.00000, saving model to ./model/84-39780772.0000.hdf5\n",
      "\n",
      "Epoch 00085: val_loss improved from 39780772.00000 to 36748720.50000, saving model to ./model/85-36748720.5000.hdf5\n",
      "\n",
      "Epoch 00086: val_loss improved from 36748720.50000 to 33896645.25000, saving model to ./model/86-33896645.2500.hdf5\n",
      "\n",
      "Epoch 00087: val_loss improved from 33896645.25000 to 31282534.75000, saving model to ./model/87-31282534.7500.hdf5\n",
      "\n",
      "Epoch 00088: val_loss improved from 31282534.75000 to 28963932.50000, saving model to ./model/88-28963932.5000.hdf5\n",
      "\n",
      "Epoch 00089: val_loss improved from 28963932.50000 to 26743382.00000, saving model to ./model/89-26743382.0000.hdf5\n",
      "\n",
      "Epoch 00090: val_loss improved from 26743382.00000 to 24816514.62500, saving model to ./model/90-24816514.6250.hdf5\n",
      "\n",
      "Epoch 00091: val_loss improved from 24816514.62500 to 22985461.00000, saving model to ./model/91-22985461.0000.hdf5\n",
      "\n",
      "Epoch 00092: val_loss improved from 22985461.00000 to 21386159.37500, saving model to ./model/92-21386159.3750.hdf5\n",
      "\n",
      "Epoch 00093: val_loss improved from 21386159.37500 to 19928075.37500, saving model to ./model/93-19928075.3750.hdf5\n",
      "\n",
      "Epoch 00094: val_loss improved from 19928075.37500 to 18606101.62500, saving model to ./model/94-18606101.6250.hdf5\n",
      "\n",
      "Epoch 00095: val_loss improved from 18606101.62500 to 17423288.25000, saving model to ./model/95-17423288.2500.hdf5\n",
      "\n",
      "Epoch 00096: val_loss improved from 17423288.25000 to 16413312.31250, saving model to ./model/96-16413312.3125.hdf5\n",
      "\n",
      "Epoch 00097: val_loss improved from 16413312.31250 to 15493283.50000, saving model to ./model/97-15493283.5000.hdf5\n",
      "\n",
      "Epoch 00098: val_loss improved from 15493283.50000 to 14717348.37500, saving model to ./model/98-14717348.3750.hdf5\n",
      "\n",
      "Epoch 00099: val_loss improved from 14717348.37500 to 14010740.50000, saving model to ./model/99-14010740.5000.hdf5\n",
      "\n",
      "Epoch 00100: val_loss improved from 14010740.50000 to 13403019.25000, saving model to ./model/100-13403019.2500.hdf5\n",
      "\n",
      "Epoch 00101: val_loss improved from 13403019.25000 to 12839001.87500, saving model to ./model/101-12839001.8750.hdf5\n",
      "\n",
      "Epoch 00102: val_loss improved from 12839001.87500 to 12351566.18750, saving model to ./model/102-12351566.1875.hdf5\n",
      "\n",
      "Epoch 00103: val_loss improved from 12351566.18750 to 11960878.00000, saving model to ./model/103-11960878.0000.hdf5\n",
      "\n",
      "Epoch 00104: val_loss improved from 11960878.00000 to 11601917.56250, saving model to ./model/104-11601917.5625.hdf5\n",
      "\n",
      "Epoch 00105: val_loss improved from 11601917.56250 to 11301603.56250, saving model to ./model/105-11301603.5625.hdf5\n",
      "\n",
      "Epoch 00106: val_loss improved from 11301603.56250 to 11066769.12500, saving model to ./model/106-11066769.1250.hdf5\n",
      "\n",
      "Epoch 00107: val_loss improved from 11066769.12500 to 10860094.93750, saving model to ./model/107-10860094.9375.hdf5\n",
      "\n",
      "Epoch 00108: val_loss improved from 10860094.93750 to 10684543.43750, saving model to ./model/108-10684543.4375.hdf5\n",
      "\n",
      "Epoch 00109: val_loss improved from 10684543.43750 to 10531140.62500, saving model to ./model/109-10531140.6250.hdf5\n",
      "\n",
      "Epoch 00110: val_loss improved from 10531140.62500 to 10395049.50000, saving model to ./model/110-10395049.5000.hdf5\n",
      "\n",
      "Epoch 00111: val_loss improved from 10395049.50000 to 10290217.18750, saving model to ./model/111-10290217.1875.hdf5\n",
      "\n",
      "Epoch 00112: val_loss improved from 10290217.18750 to 10192820.06250, saving model to ./model/112-10192820.0625.hdf5\n",
      "\n",
      "Epoch 00113: val_loss improved from 10192820.06250 to 10120570.06250, saving model to ./model/113-10120570.0625.hdf5\n",
      "\n",
      "Epoch 00114: val_loss improved from 10120570.06250 to 10063186.43750, saving model to ./model/114-10063186.4375.hdf5\n",
      "\n",
      "Epoch 00115: val_loss improved from 10063186.43750 to 9994602.06250, saving model to ./model/115-9994602.0625.hdf5\n",
      "\n",
      "Epoch 00116: val_loss improved from 9994602.06250 to 9953545.43750, saving model to ./model/116-9953545.4375.hdf5\n",
      "\n",
      "Epoch 00117: val_loss improved from 9953545.43750 to 9906604.56250, saving model to ./model/117-9906604.5625.hdf5\n",
      "\n",
      "Epoch 00118: val_loss improved from 9906604.56250 to 9871643.18750, saving model to ./model/118-9871643.1875.hdf5\n",
      "\n",
      "Epoch 00119: val_loss improved from 9871643.18750 to 9842705.12500, saving model to ./model/119-9842705.1250.hdf5\n",
      "\n",
      "Epoch 00120: val_loss improved from 9842705.12500 to 9815787.31250, saving model to ./model/120-9815787.3125.hdf5\n",
      "\n",
      "Epoch 00121: val_loss improved from 9815787.31250 to 9791367.75000, saving model to ./model/121-9791367.7500.hdf5\n",
      "\n",
      "Epoch 00122: val_loss improved from 9791367.75000 to 9768667.00000, saving model to ./model/122-9768667.0000.hdf5\n",
      "\n",
      "Epoch 00123: val_loss improved from 9768667.00000 to 9746236.75000, saving model to ./model/123-9746236.7500.hdf5\n",
      "\n",
      "Epoch 00124: val_loss improved from 9746236.75000 to 9727401.56250, saving model to ./model/124-9727401.5625.hdf5\n",
      "\n",
      "Epoch 00125: val_loss improved from 9727401.56250 to 9708137.62500, saving model to ./model/125-9708137.6250.hdf5\n",
      "\n",
      "Epoch 00126: val_loss improved from 9708137.62500 to 9686228.62500, saving model to ./model/126-9686228.6250.hdf5\n",
      "\n",
      "Epoch 00127: val_loss improved from 9686228.62500 to 9662612.25000, saving model to ./model/127-9662612.2500.hdf5\n",
      "\n",
      "Epoch 00128: val_loss improved from 9662612.25000 to 9643473.75000, saving model to ./model/128-9643473.7500.hdf5\n",
      "\n",
      "Epoch 00129: val_loss improved from 9643473.75000 to 9620737.18750, saving model to ./model/129-9620737.1875.hdf5\n",
      "\n",
      "Epoch 00130: val_loss improved from 9620737.18750 to 9597555.00000, saving model to ./model/130-9597555.0000.hdf5\n",
      "\n",
      "Epoch 00131: val_loss improved from 9597555.00000 to 9583651.00000, saving model to ./model/131-9583651.0000.hdf5\n",
      "\n",
      "Epoch 00132: val_loss improved from 9583651.00000 to 9557718.93750, saving model to ./model/132-9557718.9375.hdf5\n",
      "\n",
      "Epoch 00133: val_loss improved from 9557718.93750 to 9539544.31250, saving model to ./model/133-9539544.3125.hdf5\n",
      "\n",
      "Epoch 00134: val_loss improved from 9539544.31250 to 9501580.81250, saving model to ./model/134-9501580.8125.hdf5\n",
      "\n",
      "Epoch 00135: val_loss improved from 9501580.81250 to 9475198.31250, saving model to ./model/135-9475198.3125.hdf5\n",
      "\n",
      "Epoch 00136: val_loss improved from 9475198.31250 to 9445254.31250, saving model to ./model/136-9445254.3125.hdf5\n",
      "\n",
      "Epoch 00137: val_loss improved from 9445254.31250 to 9415637.87500, saving model to ./model/137-9415637.8750.hdf5\n",
      "\n",
      "Epoch 00138: val_loss improved from 9415637.87500 to 9392392.12500, saving model to ./model/138-9392392.1250.hdf5\n",
      "\n",
      "Epoch 00139: val_loss improved from 9392392.12500 to 9369086.81250, saving model to ./model/139-9369086.8125.hdf5\n",
      "\n",
      "Epoch 00140: val_loss improved from 9369086.81250 to 9334731.00000, saving model to ./model/140-9334731.0000.hdf5\n",
      "\n",
      "Epoch 00141: val_loss improved from 9334731.00000 to 9303457.06250, saving model to ./model/141-9303457.0625.hdf5\n",
      "\n",
      "Epoch 00142: val_loss improved from 9303457.06250 to 9278877.00000, saving model to ./model/142-9278877.0000.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00143: val_loss improved from 9278877.00000 to 9248045.50000, saving model to ./model/143-9248045.5000.hdf5\n",
      "\n",
      "Epoch 00144: val_loss improved from 9248045.50000 to 9215107.37500, saving model to ./model/144-9215107.3750.hdf5\n",
      "\n",
      "Epoch 00145: val_loss improved from 9215107.37500 to 9182902.06250, saving model to ./model/145-9182902.0625.hdf5\n",
      "\n",
      "Epoch 00146: val_loss improved from 9182902.06250 to 9150193.62500, saving model to ./model/146-9150193.6250.hdf5\n",
      "\n",
      "Epoch 00147: val_loss improved from 9150193.62500 to 9123867.81250, saving model to ./model/147-9123867.8125.hdf5\n",
      "\n",
      "Epoch 00148: val_loss improved from 9123867.81250 to 9085838.06250, saving model to ./model/148-9085838.0625.hdf5\n",
      "\n",
      "Epoch 00149: val_loss improved from 9085838.06250 to 9064574.68750, saving model to ./model/149-9064574.6875.hdf5\n",
      "\n",
      "Epoch 00150: val_loss improved from 9064574.68750 to 9034344.25000, saving model to ./model/150-9034344.2500.hdf5\n",
      "\n",
      "Epoch 00151: val_loss improved from 9034344.25000 to 9002209.06250, saving model to ./model/151-9002209.0625.hdf5\n",
      "\n",
      "Epoch 00152: val_loss improved from 9002209.06250 to 8968644.81250, saving model to ./model/152-8968644.8125.hdf5\n",
      "\n",
      "Epoch 00153: val_loss improved from 8968644.81250 to 8934469.56250, saving model to ./model/153-8934469.5625.hdf5\n",
      "\n",
      "Epoch 00154: val_loss improved from 8934469.56250 to 8905976.87500, saving model to ./model/154-8905976.8750.hdf5\n",
      "\n",
      "Epoch 00155: val_loss improved from 8905976.87500 to 8864582.93750, saving model to ./model/155-8864582.9375.hdf5\n",
      "\n",
      "Epoch 00156: val_loss improved from 8864582.93750 to 8832183.93750, saving model to ./model/156-8832183.9375.hdf5\n",
      "\n",
      "Epoch 00157: val_loss improved from 8832183.93750 to 8807767.81250, saving model to ./model/157-8807767.8125.hdf5\n",
      "\n",
      "Epoch 00158: val_loss improved from 8807767.81250 to 8769980.75000, saving model to ./model/158-8769980.7500.hdf5\n",
      "\n",
      "Epoch 00159: val_loss improved from 8769980.75000 to 8738277.50000, saving model to ./model/159-8738277.5000.hdf5\n",
      "\n",
      "Epoch 00160: val_loss improved from 8738277.50000 to 8718491.87500, saving model to ./model/160-8718491.8750.hdf5\n",
      "\n",
      "Epoch 00161: val_loss improved from 8718491.87500 to 8670982.43750, saving model to ./model/161-8670982.4375.hdf5\n",
      "\n",
      "Epoch 00162: val_loss improved from 8670982.43750 to 8641276.81250, saving model to ./model/162-8641276.8125.hdf5\n",
      "\n",
      "Epoch 00163: val_loss improved from 8641276.81250 to 8610384.12500, saving model to ./model/163-8610384.1250.hdf5\n",
      "\n",
      "Epoch 00164: val_loss improved from 8610384.12500 to 8571362.43750, saving model to ./model/164-8571362.4375.hdf5\n",
      "\n",
      "Epoch 00165: val_loss improved from 8571362.43750 to 8530150.93750, saving model to ./model/165-8530150.9375.hdf5\n",
      "\n",
      "Epoch 00166: val_loss improved from 8530150.93750 to 8492026.50000, saving model to ./model/166-8492026.5000.hdf5\n",
      "\n",
      "Epoch 00167: val_loss improved from 8492026.50000 to 8477407.87500, saving model to ./model/167-8477407.8750.hdf5\n",
      "\n",
      "Epoch 00168: val_loss improved from 8477407.87500 to 8428340.25000, saving model to ./model/168-8428340.2500.hdf5\n",
      "\n",
      "Epoch 00169: val_loss improved from 8428340.25000 to 8399285.81250, saving model to ./model/169-8399285.8125.hdf5\n",
      "\n",
      "Epoch 00170: val_loss improved from 8399285.81250 to 8349652.81250, saving model to ./model/170-8349652.8125.hdf5\n",
      "\n",
      "Epoch 00171: val_loss improved from 8349652.81250 to 8324011.87500, saving model to ./model/171-8324011.8750.hdf5\n",
      "\n",
      "Epoch 00172: val_loss improved from 8324011.87500 to 8279656.50000, saving model to ./model/172-8279656.5000.hdf5\n",
      "\n",
      "Epoch 00173: val_loss improved from 8279656.50000 to 8249910.56250, saving model to ./model/173-8249910.5625.hdf5\n",
      "\n",
      "Epoch 00174: val_loss improved from 8249910.56250 to 8219436.56250, saving model to ./model/174-8219436.5625.hdf5\n",
      "\n",
      "Epoch 00175: val_loss improved from 8219436.56250 to 8183388.37500, saving model to ./model/175-8183388.3750.hdf5\n",
      "\n",
      "Epoch 00176: val_loss improved from 8183388.37500 to 8147034.25000, saving model to ./model/176-8147034.2500.hdf5\n",
      "\n",
      "Epoch 00177: val_loss improved from 8147034.25000 to 8111420.50000, saving model to ./model/177-8111420.5000.hdf5\n",
      "\n",
      "Epoch 00178: val_loss improved from 8111420.50000 to 8072303.12500, saving model to ./model/178-8072303.1250.hdf5\n",
      "\n",
      "Epoch 00179: val_loss improved from 8072303.12500 to 8041905.75000, saving model to ./model/179-8041905.7500.hdf5\n",
      "\n",
      "Epoch 00180: val_loss improved from 8041905.75000 to 8017662.81250, saving model to ./model/180-8017662.8125.hdf5\n",
      "\n",
      "Epoch 00181: val_loss improved from 8017662.81250 to 7975536.37500, saving model to ./model/181-7975536.3750.hdf5\n",
      "\n",
      "Epoch 00182: val_loss improved from 7975536.37500 to 7936779.21875, saving model to ./model/182-7936779.2188.hdf5\n",
      "\n",
      "Epoch 00183: val_loss improved from 7936779.21875 to 7904651.56250, saving model to ./model/183-7904651.5625.hdf5\n",
      "\n",
      "Epoch 00184: val_loss improved from 7904651.56250 to 7889730.93750, saving model to ./model/184-7889730.9375.hdf5\n",
      "\n",
      "Epoch 00185: val_loss improved from 7889730.93750 to 7844932.15625, saving model to ./model/185-7844932.1562.hdf5\n",
      "\n",
      "Epoch 00186: val_loss improved from 7844932.15625 to 7794531.25000, saving model to ./model/186-7794531.2500.hdf5\n",
      "\n",
      "Epoch 00187: val_loss improved from 7794531.25000 to 7750526.46875, saving model to ./model/187-7750526.4688.hdf5\n",
      "\n",
      "Epoch 00188: val_loss improved from 7750526.46875 to 7709316.56250, saving model to ./model/188-7709316.5625.hdf5\n",
      "\n",
      "Epoch 00189: val_loss improved from 7709316.56250 to 7682781.06250, saving model to ./model/189-7682781.0625.hdf5\n",
      "\n",
      "Epoch 00190: val_loss improved from 7682781.06250 to 7640905.56250, saving model to ./model/190-7640905.5625.hdf5\n",
      "\n",
      "Epoch 00191: val_loss improved from 7640905.56250 to 7597289.53125, saving model to ./model/191-7597289.5312.hdf5\n",
      "\n",
      "Epoch 00192: val_loss improved from 7597289.53125 to 7572260.00000, saving model to ./model/192-7572260.0000.hdf5\n",
      "\n",
      "Epoch 00193: val_loss improved from 7572260.00000 to 7513304.75000, saving model to ./model/193-7513304.7500.hdf5\n",
      "\n",
      "Epoch 00194: val_loss improved from 7513304.75000 to 7476680.87500, saving model to ./model/194-7476680.8750.hdf5\n",
      "\n",
      "Epoch 00195: val_loss improved from 7476680.87500 to 7454172.96875, saving model to ./model/195-7454172.9688.hdf5\n",
      "\n",
      "Epoch 00196: val_loss improved from 7454172.96875 to 7417664.81250, saving model to ./model/196-7417664.8125.hdf5\n",
      "\n",
      "Epoch 00197: val_loss improved from 7417664.81250 to 7379551.46875, saving model to ./model/197-7379551.4688.hdf5\n",
      "\n",
      "Epoch 00198: val_loss improved from 7379551.46875 to 7337568.40625, saving model to ./model/198-7337568.4062.hdf5\n",
      "\n",
      "Epoch 00199: val_loss improved from 7337568.40625 to 7305352.56250, saving model to ./model/199-7305352.5625.hdf5\n",
      "\n",
      "Epoch 00200: val_loss improved from 7305352.56250 to 7272787.65625, saving model to ./model/200-7272787.6562.hdf5\n",
      "\n",
      "Epoch 00201: val_loss improved from 7272787.65625 to 7241153.65625, saving model to ./model/201-7241153.6562.hdf5\n",
      "\n",
      "Epoch 00202: val_loss improved from 7241153.65625 to 7188713.46875, saving model to ./model/202-7188713.4688.hdf5\n",
      "\n",
      "Epoch 00203: val_loss improved from 7188713.46875 to 7151165.81250, saving model to ./model/203-7151165.8125.hdf5\n",
      "\n",
      "Epoch 00204: val_loss improved from 7151165.81250 to 7115635.12500, saving model to ./model/204-7115635.1250.hdf5\n",
      "\n",
      "Epoch 00205: val_loss improved from 7115635.12500 to 7090110.78125, saving model to ./model/205-7090110.7812.hdf5\n",
      "\n",
      "Epoch 00206: val_loss improved from 7090110.78125 to 7044362.75000, saving model to ./model/206-7044362.7500.hdf5\n",
      "\n",
      "Epoch 00207: val_loss improved from 7044362.75000 to 7007543.12500, saving model to ./model/207-7007543.1250.hdf5\n",
      "\n",
      "Epoch 00208: val_loss improved from 7007543.12500 to 6966661.18750, saving model to ./model/208-6966661.1875.hdf5\n",
      "\n",
      "Epoch 00209: val_loss improved from 6966661.18750 to 6920369.62500, saving model to ./model/209-6920369.6250.hdf5\n",
      "\n",
      "Epoch 00210: val_loss improved from 6920369.62500 to 6881898.87500, saving model to ./model/210-6881898.8750.hdf5\n",
      "\n",
      "Epoch 00211: val_loss improved from 6881898.87500 to 6844853.37500, saving model to ./model/211-6844853.3750.hdf5\n",
      "\n",
      "Epoch 00212: val_loss improved from 6844853.37500 to 6817324.15625, saving model to ./model/212-6817324.1562.hdf5\n",
      "\n",
      "Epoch 00213: val_loss improved from 6817324.15625 to 6776416.59375, saving model to ./model/213-6776416.5938.hdf5\n",
      "\n",
      "Epoch 00214: val_loss improved from 6776416.59375 to 6749780.25000, saving model to ./model/214-6749780.2500.hdf5\n",
      "\n",
      "Epoch 00215: val_loss improved from 6749780.25000 to 6724668.43750, saving model to ./model/215-6724668.4375.hdf5\n",
      "\n",
      "Epoch 00216: val_loss improved from 6724668.43750 to 6669805.84375, saving model to ./model/216-6669805.8438.hdf5\n",
      "\n",
      "Epoch 00217: val_loss improved from 6669805.84375 to 6635626.84375, saving model to ./model/217-6635626.8438.hdf5\n",
      "\n",
      "Epoch 00218: val_loss improved from 6635626.84375 to 6586295.31250, saving model to ./model/218-6586295.3125.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00219: val_loss improved from 6586295.31250 to 6564755.53125, saving model to ./model/219-6564755.5312.hdf5\n",
      "\n",
      "Epoch 00220: val_loss improved from 6564755.53125 to 6528110.40625, saving model to ./model/220-6528110.4062.hdf5\n",
      "\n",
      "Epoch 00221: val_loss improved from 6528110.40625 to 6504106.21875, saving model to ./model/221-6504106.2188.hdf5\n",
      "\n",
      "Epoch 00222: val_loss improved from 6504106.21875 to 6459685.00000, saving model to ./model/222-6459685.0000.hdf5\n",
      "\n",
      "Epoch 00223: val_loss improved from 6459685.00000 to 6416371.00000, saving model to ./model/223-6416371.0000.hdf5\n",
      "\n",
      "Epoch 00224: val_loss improved from 6416371.00000 to 6373635.34375, saving model to ./model/224-6373635.3438.hdf5\n",
      "\n",
      "Epoch 00225: val_loss improved from 6373635.34375 to 6339406.65625, saving model to ./model/225-6339406.6562.hdf5\n",
      "\n",
      "Epoch 00226: val_loss improved from 6339406.65625 to 6306264.21875, saving model to ./model/226-6306264.2188.hdf5\n",
      "\n",
      "Epoch 00227: val_loss improved from 6306264.21875 to 6268646.71875, saving model to ./model/227-6268646.7188.hdf5\n",
      "\n",
      "Epoch 00228: val_loss improved from 6268646.71875 to 6233943.21875, saving model to ./model/228-6233943.2188.hdf5\n",
      "\n",
      "Epoch 00229: val_loss improved from 6233943.21875 to 6188904.25000, saving model to ./model/229-6188904.2500.hdf5\n",
      "\n",
      "Epoch 00230: val_loss improved from 6188904.25000 to 6158864.31250, saving model to ./model/230-6158864.3125.hdf5\n",
      "\n",
      "Epoch 00231: val_loss improved from 6158864.31250 to 6113004.00000, saving model to ./model/231-6113004.0000.hdf5\n",
      "\n",
      "Epoch 00232: val_loss improved from 6113004.00000 to 6058111.93750, saving model to ./model/232-6058111.9375.hdf5\n",
      "\n",
      "Epoch 00233: val_loss improved from 6058111.93750 to 6032793.31250, saving model to ./model/233-6032793.3125.hdf5\n",
      "\n",
      "Epoch 00234: val_loss improved from 6032793.31250 to 5989824.21875, saving model to ./model/234-5989824.2188.hdf5\n",
      "\n",
      "Epoch 00235: val_loss improved from 5989824.21875 to 5963635.25000, saving model to ./model/235-5963635.2500.hdf5\n",
      "\n",
      "Epoch 00236: val_loss improved from 5963635.25000 to 5904948.50000, saving model to ./model/236-5904948.5000.hdf5\n",
      "\n",
      "Epoch 00237: val_loss improved from 5904948.50000 to 5867224.96875, saving model to ./model/237-5867224.9688.hdf5\n",
      "\n",
      "Epoch 00238: val_loss improved from 5867224.96875 to 5846916.00000, saving model to ./model/238-5846916.0000.hdf5\n",
      "\n",
      "Epoch 00239: val_loss improved from 5846916.00000 to 5807692.68750, saving model to ./model/239-5807692.6875.hdf5\n",
      "\n",
      "Epoch 00240: val_loss improved from 5807692.68750 to 5772621.84375, saving model to ./model/240-5772621.8438.hdf5\n",
      "\n",
      "Epoch 00241: val_loss improved from 5772621.84375 to 5721278.59375, saving model to ./model/241-5721278.5938.hdf5\n",
      "\n",
      "Epoch 00242: val_loss improved from 5721278.59375 to 5691669.53125, saving model to ./model/242-5691669.5312.hdf5\n",
      "\n",
      "Epoch 00243: val_loss improved from 5691669.53125 to 5661079.75000, saving model to ./model/243-5661079.7500.hdf5\n",
      "\n",
      "Epoch 00244: val_loss improved from 5661079.75000 to 5640828.50000, saving model to ./model/244-5640828.5000.hdf5\n",
      "\n",
      "Epoch 00245: val_loss improved from 5640828.50000 to 5612451.90625, saving model to ./model/245-5612451.9062.hdf5\n",
      "\n",
      "Epoch 00246: val_loss improved from 5612451.90625 to 5582554.87500, saving model to ./model/246-5582554.8750.hdf5\n",
      "\n",
      "Epoch 00247: val_loss improved from 5582554.87500 to 5524579.25000, saving model to ./model/247-5524579.2500.hdf5\n",
      "\n",
      "Epoch 00248: val_loss improved from 5524579.25000 to 5478924.18750, saving model to ./model/248-5478924.1875.hdf5\n",
      "\n",
      "Epoch 00249: val_loss improved from 5478924.18750 to 5448975.96875, saving model to ./model/249-5448975.9688.hdf5\n",
      "\n",
      "Epoch 00250: val_loss improved from 5448975.96875 to 5412647.56250, saving model to ./model/250-5412647.5625.hdf5\n",
      "\n",
      "Epoch 00251: val_loss improved from 5412647.56250 to 5371937.93750, saving model to ./model/251-5371937.9375.hdf5\n",
      "\n",
      "Epoch 00252: val_loss improved from 5371937.93750 to 5330205.96875, saving model to ./model/252-5330205.9688.hdf5\n",
      "\n",
      "Epoch 00253: val_loss improved from 5330205.96875 to 5272869.62500, saving model to ./model/253-5272869.6250.hdf5\n",
      "\n",
      "Epoch 00254: val_loss improved from 5272869.62500 to 5242163.84375, saving model to ./model/254-5242163.8438.hdf5\n",
      "\n",
      "Epoch 00255: val_loss improved from 5242163.84375 to 5205265.34375, saving model to ./model/255-5205265.3438.hdf5\n",
      "\n",
      "Epoch 00256: val_loss improved from 5205265.34375 to 5174490.18750, saving model to ./model/256-5174490.1875.hdf5\n",
      "\n",
      "Epoch 00257: val_loss improved from 5174490.18750 to 5141151.90625, saving model to ./model/257-5141151.9062.hdf5\n",
      "\n",
      "Epoch 00258: val_loss improved from 5141151.90625 to 5098365.71875, saving model to ./model/258-5098365.7188.hdf5\n",
      "\n",
      "Epoch 00259: val_loss improved from 5098365.71875 to 5059695.93750, saving model to ./model/259-5059695.9375.hdf5\n",
      "\n",
      "Epoch 00260: val_loss improved from 5059695.93750 to 5026845.65625, saving model to ./model/260-5026845.6562.hdf5\n",
      "\n",
      "Epoch 00261: val_loss improved from 5026845.65625 to 4993819.09375, saving model to ./model/261-4993819.0938.hdf5\n",
      "\n",
      "Epoch 00262: val_loss improved from 4993819.09375 to 4948643.53125, saving model to ./model/262-4948643.5312.hdf5\n",
      "\n",
      "Epoch 00263: val_loss improved from 4948643.53125 to 4915589.15625, saving model to ./model/263-4915589.1562.hdf5\n",
      "\n",
      "Epoch 00264: val_loss improved from 4915589.15625 to 4889266.59375, saving model to ./model/264-4889266.5938.hdf5\n",
      "\n",
      "Epoch 00265: val_loss improved from 4889266.59375 to 4859491.81250, saving model to ./model/265-4859491.8125.hdf5\n",
      "\n",
      "Epoch 00266: val_loss improved from 4859491.81250 to 4818043.43750, saving model to ./model/266-4818043.4375.hdf5\n",
      "\n",
      "Epoch 00267: val_loss improved from 4818043.43750 to 4783233.03125, saving model to ./model/267-4783233.0312.hdf5\n",
      "\n",
      "Epoch 00268: val_loss improved from 4783233.03125 to 4749219.18750, saving model to ./model/268-4749219.1875.hdf5\n",
      "\n",
      "Epoch 00269: val_loss improved from 4749219.18750 to 4700259.62500, saving model to ./model/269-4700259.6250.hdf5\n",
      "\n",
      "Epoch 00270: val_loss improved from 4700259.62500 to 4653980.06250, saving model to ./model/270-4653980.0625.hdf5\n",
      "\n",
      "Epoch 00271: val_loss improved from 4653980.06250 to 4628967.25000, saving model to ./model/271-4628967.2500.hdf5\n",
      "\n",
      "Epoch 00272: val_loss improved from 4628967.25000 to 4588048.28125, saving model to ./model/272-4588048.2812.hdf5\n",
      "\n",
      "Epoch 00273: val_loss improved from 4588048.28125 to 4561219.10938, saving model to ./model/273-4561219.1094.hdf5\n",
      "\n",
      "Epoch 00274: val_loss improved from 4561219.10938 to 4525698.09375, saving model to ./model/274-4525698.0938.hdf5\n",
      "\n",
      "Epoch 00275: val_loss improved from 4525698.09375 to 4495597.50000, saving model to ./model/275-4495597.5000.hdf5\n",
      "\n",
      "Epoch 00276: val_loss improved from 4495597.50000 to 4467540.57812, saving model to ./model/276-4467540.5781.hdf5\n",
      "\n",
      "Epoch 00277: val_loss improved from 4467540.57812 to 4427468.93750, saving model to ./model/277-4427468.9375.hdf5\n",
      "\n",
      "Epoch 00278: val_loss improved from 4427468.93750 to 4401897.65625, saving model to ./model/278-4401897.6562.hdf5\n",
      "\n",
      "Epoch 00279: val_loss improved from 4401897.65625 to 4349916.71875, saving model to ./model/279-4349916.7188.hdf5\n",
      "\n",
      "Epoch 00280: val_loss improved from 4349916.71875 to 4317023.18750, saving model to ./model/280-4317023.1875.hdf5\n",
      "\n",
      "Epoch 00281: val_loss improved from 4317023.18750 to 4301133.96875, saving model to ./model/281-4301133.9688.hdf5\n",
      "\n",
      "Epoch 00282: val_loss improved from 4301133.96875 to 4248294.48438, saving model to ./model/282-4248294.4844.hdf5\n",
      "\n",
      "Epoch 00283: val_loss improved from 4248294.48438 to 4225516.92188, saving model to ./model/283-4225516.9219.hdf5\n",
      "\n",
      "Epoch 00284: val_loss improved from 4225516.92188 to 4195437.65625, saving model to ./model/284-4195437.6562.hdf5\n",
      "\n",
      "Epoch 00285: val_loss improved from 4195437.65625 to 4147984.98438, saving model to ./model/285-4147984.9844.hdf5\n",
      "\n",
      "Epoch 00286: val_loss improved from 4147984.98438 to 4114471.96875, saving model to ./model/286-4114471.9688.hdf5\n",
      "\n",
      "Epoch 00287: val_loss improved from 4114471.96875 to 4078771.40625, saving model to ./model/287-4078771.4062.hdf5\n",
      "\n",
      "Epoch 00288: val_loss improved from 4078771.40625 to 4056752.96875, saving model to ./model/288-4056752.9688.hdf5\n",
      "\n",
      "Epoch 00289: val_loss improved from 4056752.96875 to 4033877.67188, saving model to ./model/289-4033877.6719.hdf5\n",
      "\n",
      "Epoch 00290: val_loss improved from 4033877.67188 to 3993638.00000, saving model to ./model/290-3993638.0000.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00291: val_loss improved from 3993638.00000 to 3965555.71875, saving model to ./model/291-3965555.7188.hdf5\n",
      "\n",
      "Epoch 00292: val_loss improved from 3965555.71875 to 3943998.51562, saving model to ./model/292-3943998.5156.hdf5\n",
      "\n",
      "Epoch 00293: val_loss improved from 3943998.51562 to 3918754.31250, saving model to ./model/293-3918754.3125.hdf5\n",
      "\n",
      "Epoch 00294: val_loss improved from 3918754.31250 to 3871838.28125, saving model to ./model/294-3871838.2812.hdf5\n",
      "\n",
      "Epoch 00295: val_loss improved from 3871838.28125 to 3833418.70312, saving model to ./model/295-3833418.7031.hdf5\n",
      "\n",
      "Epoch 00296: val_loss improved from 3833418.70312 to 3791538.54688, saving model to ./model/296-3791538.5469.hdf5\n",
      "\n",
      "Epoch 00297: val_loss improved from 3791538.54688 to 3756634.00000, saving model to ./model/297-3756634.0000.hdf5\n",
      "\n",
      "Epoch 00298: val_loss improved from 3756634.00000 to 3728331.54688, saving model to ./model/298-3728331.5469.hdf5\n",
      "\n",
      "Epoch 00299: val_loss improved from 3728331.54688 to 3689745.45312, saving model to ./model/299-3689745.4531.hdf5\n",
      "\n",
      "Epoch 00300: val_loss improved from 3689745.45312 to 3672844.03125, saving model to ./model/300-3672844.0312.hdf5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": 24932.000, : 26994.500\n",
      ": 24098.000, : 23164.969\n",
      ": 12180.000, : 6449.115\n",
      ": 22260.000, : 21577.793\n",
      ": 22980.000, : 21839.490\n",
      ": 25300.000, : 25281.246\n",
      ": 15420.000, : 15189.938\n",
      ": 14687.000, : 11283.222\n",
      ": 29004.000, : 26322.633\n",
      ": 22811.000, : 25279.174\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "seed = 0\n",
    "numpy.random.seed(seed)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "df = pd.read_csv(\"../dataset/Factory_Salary.csv\")\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['Profession'] = le.fit_transform(df['Profession'])\n",
    "df['Equipment'] = le.fit_transform(df['Equipment'])\n",
    "df = df.drop('Date', axis = 1)\n",
    "df = df.astype('int64')\n",
    "df = df.dropna()\n",
    "\n",
    "dataset = df.values\n",
    "X = dataset[:,0:5]\n",
    "Y = dataset[:,5]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y, test_size=0.3, random_state=seed)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=5, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "MODEL_DIR = './model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n",
    "\n",
    "modelpath=\"./model/{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=300, batch_size=10, verbose=0, callbacks=[early_stopping_callback,checkpointer])\n",
    "\n",
    "y_vloss = history.history['val_loss']\n",
    "\n",
    "y_loss = history.history['loss']\n",
    "\n",
    "\n",
    "x_len = numpy.arange(len(y_loss))\n",
    "plt.plot(x_len, y_vloss, marker='.', c=\"red\", label='Testset_loss')\n",
    "plt.plot(x_len, y_loss, marker='.', c=\"blue\", label='Trainset_loss')\n",
    "\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()\n",
    "\n",
    "Y_prediction = model.predict(X_test).flatten()\n",
    "for i in range(10):\n",
    "    label = Y_test[i]\n",
    "    prediction = Y_prediction[i]\n",
    "    print(\": {:.3f}, : {:.3f}\".format(label, prediction))\n",
    "    \n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0fd210",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b14c08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66790ed4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
